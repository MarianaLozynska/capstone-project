{
 "cells": [
  {
   "cell_type": "code",
   "id": "w37rwks3o4a",
   "source": "def sensitivity_analysis(func_id, X_sample, y_sample, n_points=50):\n    \"\"\"\n    Perform sensitivity analysis by varying each dimension independently\n    \n    Args:\n        func_id: Function ID\n        X_sample: Observed inputs\n        y_sample: Observed outputs\n        n_points: Number of points to sample along each dimension\n    \"\"\"\n    from utils.bayesian_optimization import fit_gp\n    \n    dim = X_sample.shape[1]\n    \n    # Fit GP\n    gp = fit_gp(X_sample, y_sample)\n    \n    # Use best point as baseline\n    best_idx = np.argmax(y_sample)\n    baseline = X_sample[best_idx].copy()\n    \n    # Create figure\n    n_cols = min(4, dim)\n    n_rows = (dim + n_cols - 1) // n_cols\n    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))\n    if dim == 1:\n        axes = np.array([axes])\n    axes = axes.flatten()\n    \n    print(f\"\\n{'='*70}\")\n    print(f\"Function {func_id} ({dim}D) - Sensitivity Analysis\")\n    print(f\"{'='*70}\")\n    print(f\"Baseline (best point): {baseline}\")\n    print(f\"Baseline output: {y_sample[best_idx]:.6f}\\n\")\n    \n    # Analyze each dimension\n    for d in range(dim):\n        # Vary dimension d from 0 to 1\n        test_points = np.tile(baseline, (n_points, 1))\n        test_points[:, d] = np.linspace(0, 1, n_points)\n        \n        # Get GP predictions\n        mu, sigma = gp.predict(test_points, return_std=True)\n        \n        # Plot\n        ax = axes[d]\n        ax.plot(test_points[:, d], mu, 'b-', linewidth=2, label='GP mean')\n        ax.fill_between(test_points[:, d], mu - sigma, mu + sigma, alpha=0.3, label='±1σ')\n        ax.axvline(baseline[d], color='r', linestyle='--', linewidth=2, label=f'Current: {baseline[d]:.3f}')\n        ax.axhline(y_sample[best_idx], color='g', linestyle=':', linewidth=1, alpha=0.5)\n        \n        # Mark observed points in this dimension\n        obs_in_dim = X_sample[:, d]\n        ax.scatter(obs_in_dim, y_sample, c='orange', s=50, alpha=0.6, zorder=5)\n        \n        ax.set_xlabel(f'Dimension {d+1}', fontsize=11)\n        ax.set_ylabel('Predicted Output', fontsize=11)\n        ax.set_title(f'Dim {d+1} Sensitivity', fontsize=12, fontweight='bold')\n        ax.legend(fontsize=9)\n        ax.grid(alpha=0.3)\n        \n        # Calculate gradient (sensitivity)\n        gradient = np.gradient(mu)\n        max_gradient = np.max(np.abs(gradient))\n        print(f\"Dimension {d+1}: Max gradient = {max_gradient:.4f} {'(steep - important)' if max_gradient > 1 else '(flat - less important)'}\")\n    \n    # Hide unused subplots\n    for idx in range(dim, len(axes)):\n        axes[idx].set_visible(False)\n    \n    plt.tight_layout()\n    plt.show()\n    print(f\"{'='*70}\\n\")\n\n\n# Run sensitivity analysis for all functions\nprint(\"\\n\" + \"=\"*70)\nprint(\"SENSITIVITY ANALYSIS - Understanding Feature Effects\")\nprint(\"=\"*70)\nprint(\"Shows how each dimension affects output when varied independently\")\nprint(\"Steep slopes = important features, Flat = less important\\n\")\n\nfor func_id in range(1, 9):\n    X = inputs[func_id]\n    y = outputs[func_id]\n    sensitivity_analysis(func_id, X, y, n_points=50)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Week 3 - Bayesian Optimization\n",
    "\n",
    "Generate optimized recommendations for Week 3 using utility modules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')  # Add parent directory to path\n",
    "\n",
    "# Import utility modules\n",
    "from utils.bayesian_optimization import propose_next_point, get_strategy\n",
    "from utils.data_utils import (\n",
    "    load_week_data,\n",
    "    save_week_data,\n",
    "    combine_with_week_results, \n",
    "    print_data_summary\n",
    ")\n",
    "from utils.visualization import visualize_all_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 1. Load Week 2 Data\n",
    "\n",
    "Load the combined data from Week 2 (includes initial + Week 1 results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Week 2 clean data (initial + Week 1)\n",
    "inputs, outputs = load_week_data(\"../week 2/week2_clean_data.npz\")\n",
    "print_data_summary(inputs, outputs, \"Week 2 Data (Initial + Week 1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2. Add Week 2 Results\n",
    "\n",
    "**TODO: Update with actual Week 2 results when you receive them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": "# Week 2 submitted points (from Week 2 recommendations)\nweek2_inputs = {\n    1: np.array([0.400174, 0.668743]),\n    2: np.array([0.700073, 0.125362]),\n    3: np.array([0.994082, 1.000000, 0.405235]),\n    4: np.array([0.431409, 0.391102, 0.432466, 0.377774]),\n    5: np.array([0.381844, 0.303415, 1.000000, 1.000000]),\n    6: np.array([0.755469, 0.270580, 0.644099, 0.672228, 0.162862]),\n    7: np.array([0.000000, 0.342263, 0.707844, 0.246481, 0.405689, 0.778028]),\n    8: np.array([0.044443, 0.140302, 0.000000, 0.042659, 1.000000, 0.088025, 0.000000, 0.953632])\n}\n\n# Week 2 outputs (received from black box)\nweek2_outputs = {\n    1: 3.1126972846093504e-39,\n    2: 0.6138474827757134,\n    3: -0.04985944307471363,\n    4: 0.3523251399573444,\n    5: 1688.0687842580955,\n    6: -0.5209883632002658,\n    7: 1.7844832290542527,\n    8: 9.6492817382496\n}\n\n# Combine with Week 2\ninputs, outputs = combine_with_week_results(inputs, outputs, week2_inputs, week2_outputs)\nprint_data_summary(inputs, outputs, \"After Week 2\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Save Week 3 Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save combined data for Week 4\n",
    "save_week_data(inputs, outputs, \"week3_clean_data.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 4. Generate Week 3 Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 70)\nprint(\"WEEK 3 BAYESIAN OPTIMIZATION RECOMMENDATIONS\")\nprint(\"ADJUSTED BASED ON SENSITIVITY ANALYSIS\")\nprint(\"=\" * 70)\n\nweek3_recommendations = {}\n\nfor func_id in range(1, 9):\n    X = inputs[func_id]\n    y = outputs[func_id]\n    dim = X.shape[1]\n    \n    # Bounds: all inputs in [0, 1]\n    bounds = np.array([[0, 1]] * dim)\n    \n    # ADJUSTED STRATEGIES based on sensitivity analysis\n    if func_id == 1:\n        # Function 1: Lost narrow peak, flat gradients - HIGH EXPLORATION\n        acq = 'EI'\n        xi = 0.1  # INCREASED from 0.001\n        kappa = 1.0\n        reason = \"High exploration - relocate lost narrow peak (flat gradients)\"\n    elif func_id == 2:\n        # Function 2: Slight improvement, continue moderate exploration\n        acq = 'EI'\n        xi = 0.01\n        kappa = 1.5\n        reason = \"Moderate exploration - working (flat but improving)\"\n    elif func_id == 3:\n        # Function 3: Stuck on plateau, flat gradients - INCREASED EXPLORATION\n        acq = 'EI'\n        xi = 0.05  # INCREASED from 0.01\n        kappa = 1.5\n        reason = \"Increased exploration - escape plateau (all dims flat)\"\n    elif func_id == 4:\n        # Function 4: Breakthrough! Keep strategy\n        acq = 'EI'\n        xi = 0.01\n        kappa = 1.5\n        reason = \"Keep strategy - breakthrough working (balanced gradients)\"\n    elif func_id == 5:\n        # Function 5: Dims 3&4 at max, continue exploitation\n        acq = 'EI'\n        xi = 0.001\n        kappa = 1.0\n        reason = \"Exploitation - dims 3&4 maxed (steep gradients)\"\n    elif func_id == 6:\n        # Function 6: Near plateau, fine-tune\n        acq = 'EI'\n        xi = 0.001\n        kappa = 1.0\n        reason = \"Exploitation - near plateau (flat gradients)\"\n    elif func_id in [7, 8]:\n        # Functions 7-8: Near convergence, fine-tune\n        acq = 'UCB'\n        xi = 0.0001\n        kappa = 0.5\n        reason = \"Fine-tuning - near convergence (all flat)\"\n    \n    # Get recommendation\n    next_point, gp = propose_next_point(\n        X, y, bounds,\n        acq_func=acq,\n        xi=xi,\n        kappa=kappa,\n        n_restarts=50\n    )\n    \n    week3_recommendations[func_id] = next_point\n    \n    # Display results\n    current_best_idx = np.argmax(y)\n    current_best = y[current_best_idx]\n    \n    print(f\"\\n{'='*70}\")\n    print(f\"FUNCTION {func_id} ({dim}D)\")\n    print(f\"{'='*70}\")\n    print(f\"Data points: {len(y)}\")\n    print(f\"Current best: {current_best:.6f}\")\n    print(f\"Strategy: {acq} (xi={xi}, kappa={kappa})\")\n    print(f\"Reason: {reason}\")\n    print(f\"Week 3 recommended point: {next_point}\")\n    pred_mean = gp.predict(next_point.reshape(1, -1))[0]\n    pred_std = gp.predict(next_point.reshape(1, -1), return_std=True)[1][0]\n    print(f\"Predicted: {pred_mean:.6f} ± {pred_std:.6f}\")\n\nprint(f\"\\n{'='*70}\")\nprint(\"SUMMARY - Week 3 Points to Submit:\")\nprint(f\"{'='*70}\")\nfor func_id in range(1, 9):\n    point = week3_recommendations[func_id]\n    print(f\"Function {func_id}: {' – '.join([f'{x:.2f}' for x in point])}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 5. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all visualizations\n",
    "visualize_all_functions(inputs, outputs, week3_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d931d1qpv7",
   "source": "## 6. Sensitivity Analysis\n\nAnalyze individual feature effects by varying one dimension at a time",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}